from .config import *
import torch
from tqdm import tqdm
from torch.utils.data import DataLoader
from torchvision.utils import make_grid, save_image

# to create real labels (1s)
def label_real(size):
    data = torch.ones(size, 1)
    return data.to(device)


# to create fake labels (0s)
def label_fake(size):
    data = torch.zeros(size, 1)
    return data.to(device)


# function to create the noise vector
def create_noise(sample_size, nz):
    return torch.randn(sample_size, nz).to(device)


# to save the images generated by the generator
def save_generator_image(image, path):
    save_image(image, path)


# function to train the discriminator network
def train_discriminator(discriminator, optimizer, criterion, data_real, data_fake):
    b_size = data_real.size(0)
    real_label = label_real(b_size)
    fake_label = label_fake(b_size)

    optimizer.zero_grad()

    output_real = discriminator(data_real)
    loss_real = criterion(output_real, real_label)

    output_fake = discriminator(data_fake)
    loss_fake = criterion(output_fake, fake_label)

    loss_real.backward()
    loss_fake.backward()
    optimizer.step()

    return loss_real + loss_fake


# function to train the generator network
def train_generator(generator, discriminator, optimizer, criterion, data_fake):
    b_size = data_fake.size(0)
    real_label = label_real(b_size)

    optimizer.zero_grad()

    output = discriminator(data_fake)
    loss = criterion(output, real_label)

    loss.backward()
    optimizer.step()

    return loss


def training_procedure(
    generator, discriminator, optim_g, optim_d, criterion, train_data
):
    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
    # create the noise vector
    noise = create_noise(sample_size, nz)
    losses_g = []  # to store generator loss after each epoch
    losses_d = []  # to store discriminator loss after each epoch
    images = []  # to store images generatd by the generator

    generator.train()
    discriminator.train()

    for epoch in range(epochs):
        loss_g = 0.0
        loss_d = 0.0
        for bi, data in tqdm(
            enumerate(train_loader),
            total=int(len(train_data) / train_loader.batch_size),
        ):
            image, _ = data
            image = image.to(device)
            b_size = len(image)
            # run the discriminator for k number of steps
            for step in range(k):
                data_fake = generator(create_noise(b_size, nz)).detach()
                data_real = image
                # train the discriminator network
                loss_d += train_discriminator(
                    discriminator, optim_d, criterion, data_real, data_fake
                )
            data_fake = generator(create_noise(b_size, nz))
            # train the generator network
            loss_g += train_generator(
                generator, discriminator, optim_g, criterion, data_fake
            )

        # create the final fake image for the epoch
        generated_img = generator(noise).cpu().detach()
        # make the images as grid
        generated_img = make_grid(generated_img)
        # save the generated torch tensor models to disk
        save_generator_image(generated_img, f"output/gen_img{epoch}.png")
        images.append(generated_img)
        epoch_loss_g = loss_g / bi  # total generator loss for the epoch
        epoch_loss_d = loss_d / bi  # total discriminator loss for the epoch
        losses_g.append(epoch_loss_g)
        losses_d.append(epoch_loss_d)

        print(f"Epoch {epoch} of {epochs}")
        print(
            f"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}"
        )
    return generator, discriminator, images
