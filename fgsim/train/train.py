from contextlib import nullcontext

import torch
import torch.autograd.profiler as profiler
from torch.utils.data import DataLoader
from torchvision.utils import save_image
from tqdm import tqdm

from ..config import conf, device
from .control import traincac


# to create real labels (1s)
def label_real(size):
    data = torch.ones(size, 1)
    return data.to(device)


# to create fake labels (0s)
def label_fake(size):
    data = torch.zeros(size, 1)
    return data.to(device)


# function to create the noise vector
def create_noise(sample_size, nz):
    return torch.randn(sample_size, nz).to(device)


# to save the images generated by the generator
def save_generator_image(image, path):
    save_image(image, path)


# function to train the discriminator network
def train_discriminator(discriminator, optimizer, criterion, data_real, data_fake):
    b_size = data_real.size(0)
    real_label = label_real(b_size)
    fake_label = label_fake(b_size)

    optimizer.zero_grad()

    output_real = discriminator(data_real)
    loss_real = criterion(output_real, real_label)

    output_fake = discriminator(data_fake)
    loss_fake = criterion(output_fake, fake_label)

    loss_real.backward()
    loss_fake.backward()
    optimizer.step()

    return loss_real + loss_fake


# function to train the generator network
def train_generator(generator, discriminator, optimizer, criterion, data_fake):
    b_size = data_fake.size(0)
    real_label = label_real(b_size)

    optimizer.zero_grad()

    output = discriminator(data_fake)
    loss = criterion(output, real_label)

    loss.backward()
    optimizer.step()

    return loss


def training_procedure(c: traincac):
    # Make the configuration locally available
    batch_size, epochs, k, nz, sample_size = (
        conf.model.gan[x] for x in ["batch_size", "epochs", "k", "nz", "sample_size"]
    )
    with nullcontext():
        train_loader = DataLoader(c.train_data, batch_size=2, shuffle=True)
        # create the noise vector
        noise = create_noise(sample_size, nz)
        losses_g = []  # to store generator loss after each epoch
        losses_d = []  # to store discriminator loss after each epoch
        images = []  # to store images generatd by the generator

        c.generator.train()
        c.discriminator.train()

        for epoch in range(epochs):
            loss_g = 0.0
            loss_d = 0.0
            for bi, image in tqdm(
                enumerate(train_loader),
                total=int(len(c.train_data) / train_loader.batch_size),
            ):
                with profiler.profile(profile_memory=True, record_shapes=True) as prof:
                    image = image.to(device)
                    b_size = len(image)

                    # run the discriminator for k number of steps
                    for _ in range(k):
                        data_fake = c.generator(create_noise(b_size, nz)).detach()
                        data_real = image
                        # train the discriminator network
                        loss_d += train_discriminator(
                            c.discriminator,
                            c.optim_d,
                            c.criterion,
                            data_real,
                            data_fake,
                        )
                    data_fake = c.generator(create_noise(b_size, nz))
                    # train the generator network
                    loss_g += train_generator(
                        c.generator, c.discriminator, c.optim_g, c.criterion, data_fake
                    )
            print(prof.key_averages().table(sort_by="cpu_memory_usage", row_limit=10))
            # create the final fake image for the epoch
            generated_img = c.generator(noise).cpu().detach()
            # shape : sample_size * x * y *z

            # save the generated torch tensor models to disk (img 1, 7)
            if epoch % 10 == 0:
                save_generator_image(
                    generated_img[0, :, :, 7], f"wd/{conf.tag}/gen_img{epoch}.png"
                )
                c.save_model()
            images.append(generated_img)
            epoch_loss_g = loss_g / bi  # total generator loss for the epoch
            epoch_loss_d = loss_d / bi  # total discriminator loss for the epoch
            losses_g.append(epoch_loss_g)
            losses_d.append(epoch_loss_d)

            print(f"Epoch {epoch} of {epochs}")
            print(
                f"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}"
            )

    from matplotlib import pyplot as plt

    # plot and save the generator and discriminator loss
    plt.figure()
    plt.plot(losses_g, label="Generator loss")
    plt.plot(losses_d, label="Discriminator Loss")
    plt.legend()
    plt.savefig("output/loss.png")

    return c.generator, c.discriminator, images
