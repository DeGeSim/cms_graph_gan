tag: default
loglevel: 20
loglevel_qf: 30
seed: 0
comet_project_name: "hgcal"
ray: False
remote: False

models:
    gen:
        name: gen_deeptree
        params: ${model_param_options[${models.gen.name}]}
        losses: "${optionlist:${loss_options},${models.gen.losses_list}}"
        losses_list: ${listadd:${gan_mode_options[${training.gan_mode}][gen]},${models.gen.additional_losses_list}}
        additional_losses_list: ["dcd"]
        optim:
            name: Adam
            params: ${optim_options[${models.gen.optim.name}]}
        retain_graph_on_backprop: True
    disc:
        name: disc_mp
        params: ${model_param_options[${models.disc.name}]}
        losses: "${optionlist:${loss_options},${models.disc.losses_list}}"
        losses_list: ${gan_mode_options[${training.gan_mode}][disc]}
        optim:
            name: Adam
            params:
                lr: 3.0e-4
        retain_graph_on_backprop: False

gan_mode_options:
    CE:
        gen: [CEGenLoss]
        disc: [CEDiscLoss]
    W:
        gen: [WGenLoss]
        disc: [WDiscLoss, GradientPenalty]
    MSE:
        gen: [MSEGenLoss]
        disc: [MSEDiscLoss]

ffn:
    activation: LeakyReLU
    hidden_layer_size: 512
    n_layers: 3
    activation_params:
        LeakyReLU:
            negative_slope: 0.1
        ReLU: {}
        SELU: {}
    init_weights_bias_const: 0.1
    init_weights: xavier_uniform_
    norm: batchnorm
    dropout: False

layer_options:
    DeepConv:
        add_self_loops: True
        nns: upd
        msg_nn_include_edge_attr: False
        msg_nn_include_global: False
        msg_nn_final_linear: True
        upd_nn_include_global: True
        upd_nn_final_linear: True
        residual: False
    GINConv:
        final_linear: True
    GINCConv:
        final_linear: True

model_param_options:
    gen_deeptree:
        n_global: 0
        n_cond: ${len:${loader.y_features}}
        all_points: False
        branching_param:
            residual: True
            final_linear: True
            norm: none
        connect_all_ancestors: True
        ancestor_mpl:
            n_mpl: 0
            n_hidden_nodes: 1440
            conv_name: GINConv
            skip_connecton: True
            layer_param: ${layer_options[${model_param_options.gen_deeptree.ancestor_mpl.conv_name}]}
        child_mpl:
            n_mpl: 0
            n_hidden_nodes: 1960
            conv_name: GINConv
            skip_connecton: True
            layer_param: ${layer_options[${model_param_options.gen_deeptree.child_mpl.conv_name}]}
        final_layer_scaler: False
    gen_treepc:
        features: [96, 64, 64, 64, 64, 64, 4]
        degrees: [2, 2, 2, 2, 2, 64]
        support: 10
    gen_edgeconv:
        n_layers: 5
        n_features: 2
        n_global: 5
    gen_linear:
        random_size: 64
        n_points: ${loader[n_points]}
        n_features: ${loader[n_features]}
        batch_size: ${loader[batch_size]}
    gen_fake: {}
    gen_moons: {}
    disc_fake: {}
    disc_hlvs: {}
    disc_benno: {}
    disc_gat:
      n_features: ${loader[n_features]}
      n_points: ${loader[n_points]}
      n_cond: ${len:${loader.y_features}}
    disc_clic:
        n_features: ${loader[n_features]}
        n_prop: 20
        n_global: 2
        n_nn: 8
    disc_clicgat: ${model_param_options[disc_clic]}
    disc_graphgym:
        n_features: ${loader[n_features]}
        n_nn: 8
    disc_treepc:
        features: ${tree[features]} # [4, 64, 128, 256]
    disc_pointnet:
        batch_size: ${loader[batch_size]}
        n_points: ${loader[n_points]}
        n_features: ${loader[n_features]}
    disc_pointnet2: ${model_param_options[disc_pointnet]}
    disc_prog:
        leveldisc: disc_graphgym
        levelparams: ${model_param_options[disc_graphgym]}
    disc_pointnetmix:
        pointnetd_fc: [512]
        node_feat_size: 3
        leaky_relu_alpha: 0.2
        pointnetd_pointfc: [64, 128, 1024]
        num_hits: ${loader.n_points}
        mask: false
    disc_pcgan:
        modus: latent
        latent_dim: 128
        z1_dim: 256
        z2_dim: 10
        d_dim: 256
        pool: "max1"

    gen_mp:
        num_particles: ${loader.n_points}
        hidden_node_size: 32
        fe_layers: [96, 160, 192]
        fn_layers: [256, 256]
        fn1_layers: null # end common
        mp_iters: 2
        fe1_layers: null
        final_activation: tanh
        output_node_size: ${loader.n_features}
        input_node_size: 32 # 0 for gen_fc and gen_graphcnn
        lfc: false
        lfc_latent_size: 128
    disc_mp:
        num_particles: ${loader.n_points}
        hidden_node_size: 32
        fe_layers: [25, 25, 25]
        fn_layers: [256, 256]
        fn1_layers: null # end common
        mp_iters: 2
        fe1_layers: null
        final_activation: ""
        dea: true
        dea_sum: true
        fnd: []
        mask_fnd_np: false
        input_node_size: ${loader.n_features}

mpgan_mask:
    mask_feat: False
    mask_feat_bin: False
    mask_weights: False
    mask_manual: False
    mask_exp: False
    mask_real_only: False
    mask_learn: False
    mask_learn_bin: True
    mask_learn_sep: False
    fmg: [64]
    mask_disc_sep: False
    mask_fnd_np: False
    mask_c: True
    mask_fne_np: False

tree:
    branches: [2, 4, 16]
    features:
        - 512
        - 128
        - 16
        - ${loader.n_features}
# tree:
#     branches: [2, 3, 5]
#     features: [64, 32, 16, "${loader.n_features}"]

loss_options:
    WGenLoss:
        factor: 1.0
    WDiscLoss:
        factor: 1.0
    MSEDiscLoss:
        factor: 1.0
    MSEGenLoss:
        factor: 1.0
    CEDiscLoss:
        factor: 1.0
    CEGenLoss:
        factor: 1.0
    GradientPenalty:
        factor: 1.0
        gamma: 1.0
    mean_dist:
        factor: 1.0
    physics:
        factor: 1.0
    frechetpcdist:
        factor: 1.0
    outside_interval:
        factor: 1.0
        high: 4.0
        low: -4.0
    mmd:
        factor: 1.0
        kernel: "rbf"
        bandwidth: [10, 15, 20, 50]
    mmdpc:
        factor: 1.0
        kernel: "rbf"
        bandwidth: [10, 15, 20, 50]
        batch_wise: False
    fd:
        factor: 0.001
    dcd:
        factor: 1.0
        alpha: 10
        lpnorm: 1
        batch_wise: false
        pow: 2
    cd:
        factor: 1.0
        lpnorm: 1
        batch_wise: False
        pow: 1

optim_options:
    Adam:
        weight_decay: 1.0e-4
        lr: 2.e-4
    SGD:
        lr: 2.e-4
    RMSprop:
        lr: 0.0001
    FakeOptimizer: {}

smoothing_options:
    default:
        active: False
    moons: ${smoothing_options[default]}
    jetnet: ${smoothing_options[default]}
    hgcal:
        active: True
        stds: [0, 0.315, 0.18, .3] # [0, 0.315, 0.2, .15]
        decay: 1e-5
    hgcal_soham: ${smoothing_options[hgcal]}
    pcgraph: ${smoothing_options[hgcal]}


training:
    gan_mode: CE
    disc_steps_per_gen_step: 2
    early_stopping:
        validation_steps: 50
        improvement: 0.2
    checkpoint_minutes: 15
    smoothing: "${smoothing_options[${loader_name}]}"
    log_interval: 10
    max_epochs: 300
    val:
        interval: "${div:40000,${loader.batch_size}}"
        use_for_stopping: ["w1E", "w1x", "w1y", "w1layer"]
        metrics:
            - "ft_w1"
            - "aoc"
testing:
    n_events: 2000

path:
    dataset: "${loader.dataset_path}"
    dataset_processed: "${path.dataset}/pkl_${loader_name}_${loader_hash}"
    ds_lenghts: "${path.dataset_processed}/filelengths.yaml"
    training: "${path.dataset_processed}/training"
    validation: "${path.dataset_processed}/validation.pt"
    test: "${path.dataset_processed}/test.pt"
    training_glob: "*.pt"
    geo_lup: "data/geo_hgcal/DetIdLUT.root"
    run_path: "wd/${tag}/${hash}"
    tensorboard: "${path.run_path}/tb"
    checkpoint: "${path.run_path}/checkpoint.torch"
    checkpoint_old: "${path.run_path}/checkpoint_old.torch"
    state: "${path.run_path}/state.yaml"
    state_old: "${path.run_path}/state_old.yaml"
    comet_exp_key: "${path.run_path}/comet_experiment_key"

loader: "${merge:${loader_options[default]},${loader_options[${loader_name}]}}"
loader_name: pcgraph

loader_options:
    default:
        rootprefix: "treeMaker/tree"
        dataset_glob: "**/*.root"
        preprocess_training: True
        chunk_size: 1000
        batch_size: 200
        validation_set_size: 10000
        test_set_size: 50000
        scaling_fit_size: 10000
        events_per_file: 10000
        prefetch_batches: 10
        n_workers_transform: 30
        n_workers_stack: 1
        n_workers_postprocess: 1
        n_features: ${len:${loader.x_features}}
    hgcal:
        dataset_path: "~/fgsim/data/hgcal_william"
        n_points: 128
        batch_size: 50
        braches:
            id: "simHit_detid"
            energy: "genPh_E"
            hit_energy: "simHit_E"
        x_features: ["E", "x", "y", "layer"]
        y_features: ["E"]
    hgcal_soham:
        dataset_path: "~/fgsim/data/soham_pi0"
        n_points: 128
        batch_size: 50
        braches:
            id: "simHit_detid"
            energy: "genPh_E"
            hit_energy: "simHit_E"
        y_features: ["Egen", "eta", "phi"]
        x_features: ["E_hit", "x", "y", "layer"]
    pcgraph: ${loader_options[hgcal]}
    moons:
        dataset_path: "~/fgsim/data/moons"
        x_features: ["x", "y"]
        y_features: []
        n_points: 128
        batch_size: 200
        cluster_tree: false
        cluster_method: "random"
    jetnet:
        dataset_path: "~/fgsim/data/jetnet"
        n_points: 30
        x_features: ["etarel", "phirel", "ptrel"]
        y_features: ["pt", "eta", "mass", "num_particles"]
        dataset_glob: "**/t.hdf5"
        chunk_size: 5000
        batch_size: 200
