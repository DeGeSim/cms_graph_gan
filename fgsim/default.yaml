tag: default
loglevel: 20
loglevel_qf: 30
seed: 0
comet_project_name: "jetnet"
ray: False

models:
    gen:
        name: gen_deeptree
        params: ${model_param_options[${models.gen.name}]}
        losses: "${optionlist:${loss_options},${models.gen.losses_list}}"
        losses_list: ${listadd:${gan_mode_options[${training.gan_mode}][gen]},${models.gen.additional_losses_list}}
        additional_losses_list: ["dcd"]
        optim:
            name: Adam
            params:
                lr: 2.0e-4
        retain_graph_on_backprop: True
    disc:
        name: disc_mp
        params: ${model_param_options[${models.disc.name}]}
        losses: "${optionlist:${loss_options},${models.disc.losses_list}}"
        losses_list: ${gan_mode_options[${training.gan_mode}][disc]}
        optim:
            name: Adam
            params:
                lr: 1.0e-4
        retain_graph_on_backprop: False

gan_mode_options:
    CE:
        gen: [CEGenLoss]
        disc: [CEDiscLoss]
    W:
        gen: [WGenLoss]
        disc: [WDiscLoss, GradientPenalty]
    MSE:
        gen: [MSEGenLoss]
        disc: [MSEDiscLoss]

ffn:
    activation: LeakyReLU
    hidden_layer_size: 128
    n_layers: 5
    activation_params:
        LeakyReLU:
            negative_slope: 0.1
        ReLU: {}
        SELU: {}
    init_weights_bias_const: 0.1
    init_weights: kaiming_uniform_
    batchnorm: True
    dropout: True

model_param_options:
    gen_treepc:
        features: [96, 64, 64, 64, 64, 64, 4]
        degrees: [2, 2, 2, 2, 2, 64]
        support: 10
    gen_deeptree:
        n_global: 3
        final_layer_scaler: True
        all_points: False
        conv_parem:
            add_self_loops: True
            nns: both
            msg_nn_include_edge_attr: False
            msg_nn_include_global: False
            upd_nn_include_global: True
            residual: True
        branching_param:
            residual: True
        child_param:
            n_mpl: 0
            n_hidden_nodes: 512
    gen_edgeconv:
        n_layers: 5
        n_features: 2
        n_global: 5
    gen_linear:
        random_size: 64
        n_points: ${loader[n_points]}
        n_features: ${loader[n_features]}
        batch_size: ${loader[batch_size]}
    gen_moons: {}
    disc_clic:
        n_features: ${loader[n_features]}
        n_prop: 20
        n_global: 2
        n_nn: 8
    disc_clicgat: ${model_param_options[disc_clic]}
    disc_graphgym:
        n_features: ${loader[n_features]}
        n_nn: 8
    disc_hlvs: {}
    disc_treepc:
        features: ${tree[features]} # [4, 64, 128, 256]
    disc_pointnet:
        batch_size: ${loader[batch_size]}
        n_points: ${loader[n_points]}
        n_features: ${loader[n_features]}
    disc_pointnet2: ${model_param_options[disc_pointnet]}
    disc_prog:
        leveldisc: disc_graphgym
        levelparams: ${model_param_options[disc_graphgym]}
    disc_fake: {}
    disc_pointnetmix:
        pointnetd_fc: [512]
        node_feat_size: 3
        leaky_relu_alpha: 0.2
        pointnetd_pointfc: [64, 128, 1024]
        num_hits: ${loader.n_points}
        mask: false
    disc_pcgan:
        modus: latent
        latent_dim: 128
        z1_dim: 256
        z2_dim: 10
        d_dim: 256
        pool: "max1"

    gen_mp:
        num_particles: 30
        hidden_node_size: 32
        fe_layers: [96, 160, 192]
        fn_layers: [256, 256]
        fn1_layers: null # end common
        mp_iters: 2
        fe1_layers: null
        final_activation: tanh
        output_node_size: 3
        input_node_size: 32 # 0 for gen_fc and gen_graphcnn
        lfc: false
        lfc_latent_size: 128
    disc_mp:
        num_particles: 30
        hidden_node_size: 32
        fe_layers: [96, 160, 192]
        fn_layers: [256, 256]
        fn1_layers: null # end common
        mp_iters: 2
        fe1_layers: null
        final_activation: ""
        dea: true
        dea_sum: true
        fnd: []
        mask_fnd_np: false
        input_node_size: 3

mpgan_mask:
    mask_feat: False
    mask_feat_bin: False
    mask_weights: False
    mask_manual: False
    mask_exp: False
    mask_real_only: False
    mask_learn: False
    mask_learn_bin: True
    mask_learn_sep: False
    fmg: [64]
    mask_disc_sep: False
    mask_fnd_np: False
    mask_c: True
    mask_fne_np: False

tree:
    branches: [2, 3, 5]
    features: [256, 64, 32, 3]

loss_options:
    WGenLoss:
        factor: 1.0
    WDiscLoss:
        factor: 1.0
    MSEDiscLoss:
        factor: 1.0
    MSEGenLoss:
        factor: 1.0
    CEDiscLoss:
        factor: 1.0
    CEGenLoss:
        factor: 1.0
    GradientPenalty:
        factor: 1.0
        gamma: 1.0
    mean_dist:
        factor: 1.0
    physics:
        factor: 1.0
    frechetpcdist:
        factor: 1.0
    outside_interval:
        factor: 1.0
        high: 4.0
        low: -4.0
    mmd:
        factor: 1.0
        kernel: "rbf"
        bandwidth: [10, 15, 20, 50]
    mmdpc:
        factor: 1.0
        kernel: "rbf"
        bandwidth: [10, 15, 20, 50]
        batch_wise: True
    dcd:
        factor: 1.0
        alpha: 1
        lpnorm: 1
        batch_wise: True
        pow: 1
    cd:
        factor: 1.0
        lpnorm: 1
        batch_wise: True
        pow: 1

optim_options:
    Adam:
        weight_decay: 1.0e-4
        lr: 2.e-4
    SGD:
        lr: 2.e-4
    RMSprop:
        lr: 0.0001
    FakeOptimizer: {}

training:
    gan_mode: CE
    disc_steps_per_gen_step: 5
    early_stopping:
        validation_steps: 1
        improvement: 0.2
    checkpoint_minutes: 15
    smooth_features: False
    smoothing_vars: [0.0, 0.01, 0.002, 0.0001]
    log_interval: 500
    max_epochs: 300
    val:
        interval: "${div:50000,${loader.batch_size}}"
        use_for_stopping: [fpnd]
        metrics:
            w1m: {}
            w1p: {}
            fpnd: {}
            # aoc: {}
testing:
    n_events: 2000

path:
    dataset: "${loader.dataset_path}"
    dataset_processed: "${path.dataset}/pkl_${loader_name}_${loader_hash}"
    ds_lenghts: "${path.dataset_processed}/filelengths.yaml"
    training: "${path.dataset_processed}/training"
    validation: "${path.dataset_processed}/validation.pt"
    test: "${path.dataset_processed}/test.pt"
    training_glob: "*.pt"
    geo_lup: "data/geo_hgcal/DetIdLUT.root"
    run_path: "wd/${tag}/${hash}"
    full_config: "${path.run_path}/full_config.yaml"
    tensorboard: "${path.run_path}/tb"
    checkpoint: "${path.run_path}/checkpoint.torch"
    checkpoint_old: "${path.run_path}/checkpoint_old.torch"
    state: "${path.run_path}/state.yaml"
    state_old: "${path.run_path}/state_old.yaml"
    comet_exp_key: "${path.run_path}/comet_experiment_key"

loader: "${merge:${loader_options[default]},${loader_options[${loader_name}]}}"
loader_name: jetnet

loader_options:
    default:
        rootprefix: "treeMaker/tree"
        dataset_glob: "**/*.root"
        preprocess_training: True
        chunk_size: 1000
        batch_size: 100
        validation_set_size: 1000
        test_set_size: 5000
        scaling_fit_size: 100
        events_per_file: 10000
        prefetch_batches: 10
        n_workers_transform: 30
        n_workers_stack: 1
        n_workers_postprocess: 1
        n_features: ${len:${loader.cell_prop_keys}}
    hgcal:
        dataset_path: "~/fgsim/data/hgcal_william"
        n_points: 128
        braches:
            id: "simHit_detid"
            energy: "genPh_E"
            hit_energy: "simHit_E"
        cell_prop_keys: ["E", "x", "y", "layer"]
    pcgraph: ${loader_options[hgcal]}
    moons:
        dataset_path: "~/fgsim/data/moons"
        cell_prop_keys: ["x", "y"]
        n_points: 512
        cluster_tree: false
        cluster_method: "random"
    jetnet:
        dataset_path: "~/fgsim/data/jetnet"
        n_points: 30
        cell_prop_keys: ["eta", "phi", "pt"]
        dataset_glob: "**/*.csv"
        chunk_size: 5000
        batch_size: 200
        validation_set_size: 10000
        test_set_size: 50000
