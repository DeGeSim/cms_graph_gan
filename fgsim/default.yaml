tag: default
loglevel: 1
seed: 0
comet_project_name: "gan"

models:
    gen:
        name: gen_deeptree_pc
        params: ${model_param_options[${models.gen.name}]}
        losses: "${optionlist:${loss_options},${models.gen.losses_list}}"
        losses_list: [WGenLoss]
        optim:
            name: Adam
            params: ${optim_options[Adam]}
    disc:
        name: disc_hlvs
        params: ${model_param_options[${models.disc.name}]}
        losses: "${optionlist:${loss_options},${models.disc.losses_list}}"
        losses_list: [WDiscLoss,GradientPenalty]
        optim:
            name: Adam
            params: ${optim_options[Adam]}

model_param_options:
    gen_treepc:
        features: [96, 64, 64, 64, 64, 64, 4]
        degrees: [2, 2, 2, 2, 2, 64]
        support: 10
    gen_deeptree_pc:
        n_hidden_features: 3
        n_global: 4
        n_branches: 2
        n_levels: 12
        post_gen_mp_steps: 9
        conv_during_branching: False
        conv_name: AncestorConv
        n_events: "${loader.batch_size}"
        conv_parem: ${conv_options[${models.gen.params.conv_name}]}
    disc_hlvs: {}
    disc_graphgym: {}
    disc_treepc:
        features: [4, 64, 128, 256]

conv_options:
    GINConv: {}
    AncestorConv: {}


loss_options:
    WGenLoss:
        factor: 1.0
    WDiscLoss:
        factor: 1.0
    CEDiscLoss:
        factor: 1.0
    CEGenLoss:
        factor: 1.0
    GradientPenalty:
        factor: 1.0
        gamma: 1.0
    mean_dist:
        factor: 1.0
    physics:
        factor: 1.0
    frechetpcdist:
        factor: 1.0

optim_options:
    Adam:
        weight_decay: 0.0001
        lr: 0.0002
    SGD:
        lr: 0.0002

training:
    events_processed_before_validation: 100000
    disc_steps_per_gen_step: 2
    early_stopping:
        validation_steps: 15
        improvement: 0.02
    checkpoint_minutes: 30
validation:
    interval: "${div:${training.events_processed_before_validation},${loader.batch_size}}"
    stop_key: stop_key
    metrics:
        hlv_w1:
            factor: 1.0
            wgrad: False
            foreach_hlv: True
testing:
    n_events: 2000

path:
    dataset: "${loader.dataset_path}"
    # dataset: "data/hgcal_william"
    dataset_glob: "**/*.root"
    dataset_processed: "${path.dataset}/pkl_${loader_name}_${loader_hash}"
    ds_lenghts: "${path.dataset_processed}/filelengths.yaml"
    validation: "${path.dataset_processed}/validation.pt"
    test: "${path.dataset_processed}/test.pt"
    training: "${path.dataset_processed}/training"
    training_glob: "*.pt"
    geo_lup: "data/geo_hgcal/DetIdLUT.root"
    run_path: "wd/${tag}/${hash}"
    full_config: "${path.run_path}/full_config.yaml"
    tensorboard: "${path.run_path}/tb"
    checkpoint: "${path.run_path}/checkpoint.torch"
    checkpoint_old: "${path.run_path}/checkpoint_old.torch"
    state: "${path.run_path}/state.yaml"
    state_old: "${path.run_path}/state_old.yaml"
    comet_exp_key: "${path.run_path}/comet_experiment_key"
    log: "${path.run_path}/${command}.log"
    loader_log: "${path.run_path}/${command}_loader.log"

loader: "${merge:${loader_options[default]},${loader_options[${loader_name}]}}"
loader_name: puregraph

loader_options:
    default:
        rootprefix: "treeMaker/tree"
        preprocess_training: True
        debug: False
        braches:
            id: "simHit_detid"
            energy: "genPh_E"
            hit_energy: "simHit_E"
        cell_prop_keys: ["E","x", "y", "z"]
        n_features: 4
        chunksize: 100
        batch_size: 50
        validation_set_size: 5000
        test_set_size: 30000
        prefetch_batches: 2
        num_workers_transform: 10
        num_workers_stack: 1
        num_workers_postprocess: 5
        max_points: 4085
        dataset_path: "data/hgcal_william"
    hgcal:
        cell_prop_keys: ["x", "y", "z", "celltype", "issilicon"]
        batch_size: 100
    pcgraph:
        debug: True
    puregraph:
        preprocess_training: False
    normal:
        cell_prop_keys: ["x", "y"]
        n_features: 2
        # chunksize: 5000
        events_per_file: 10000
        max_points: 511
        dataset_path: "data/normal"
