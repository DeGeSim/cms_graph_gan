tag: default
loglevel: 1
seed: 0

models:
    gen:
        name: gen_treepc
        param:
            features: [96, 64, 64, 64, 64, 64, 4]
            degrees: [2, 2, 2, 2, 2, 64]
            support: 10
        losses:
            WGenLoss: ${loss_options[WGenLoss]}
        optim:
            name: Adam
            params: ${optim_options[Adam]}
    disc:
        name: disc_treepc
        param:
            features: [4, 64, 128, 256, 512, 1024]
        losses:
            WDiscLoss: ${loss_options[WDiscLoss]}
            GradientPenalty: ${loss_options[GradientPenalty]}
        optim:
            name: Adam
            params: ${optim_options[Adam]}

loss_options:
    WGenLoss:
        factor: 1.0
    WDiscLoss:
        factor: 1.0
    GradientPenalty:
        factor: 1.0
        gamma: 1.0
optim_options:
    Adam:
        weight_decay: 0.0001
        lr: 0.0002
    SGD:
        lr: 0.0002

training:
    events_processed_before_validation: 100000
    validation_interval: "${div:${training.events_processed_before_validation},${loader.batch_size}}"
    disc_steps_per_gen_step: 10
    early_stopping:
        validation_steps: 40
        improvement: 0.02

path:
    dataset: "data/hgcal_william"
    dataset_glob: "**/*.root"
    dataset_processed: "${path.dataset}/pkl_${loader_name}_${loaderhash}"
    ds_lenghts: "${path.dataset_processed}/filelengths.yaml"
    validation: "${path.dataset_processed}/validation.pt"
    test: "${path.dataset_processed}/test.pt"
    training: "${path.dataset_processed}/training"
    training_glob: "*.pt"
    geo_lup: "data/geo_hgcal/DetIdLUT.root"
    run_path: "wd/${tag}/${hash}"
    train_config: "${path.run_path}/resulting_train_config.yaml"
    full_config: "${path.run_path}/full_config.yaml"
    tensorboard: "${path.run_path}/tb"
    checkpoint: "${path.run_path}/checkpoint.torch"
    checkpoint_old: "${path.run_path}/checkpoint_old.torch"
    state: "${path.run_path}/state.torch"
    state_old: "${path.run_path}/state_old.torch"
    predict_csv: "${path.run_path}/prediction.csv"
    comet_exp_key: "${path.run_path}/comet_experiment_key"
    log: "${path.run_path}/log"

loader: ${loader_options[${loader_name}]}

loader_options:
    clic:
        qf_seq_name: "clic_seq"
        keylist:
            [
                "energy",
                "ECAL",
                "ECAL_E",
                "HCAL",
                "HCAL_E",
                "recoEta",
                "recoPhi",
                "recoTheta",
            ]
        chunksize: 100
        batch_size: 100
        validation_set_size: 5000
        test_set_size: 30000
        prefetch_batches: 2
        num_workers_transform: 1
        num_workers_stack: 1
    hgcal:
        qf_seq_name: "hgcal_seq"
        rootprefix: "treeMaker/tree"
        preprocess_training: True
        keylist: ["genPh_E", "simHit_detid", "simHit_E"]
        hlvs:
            [
                "sum_energy",
                "num_isolated",
                "isolated_energy",
                "isolated_E_fraction",
                "x_mean",
                "x_std",
                "x_mom3",
                "y_mean",
                "y_std",
                "y_mom3",
                "z_mean",
                "z_std",
                "z_mom3",
            ]
        cell_prop_keys: ["x", "y", "z", "celltype", "issilicon"]
        braches:
            id: "simHit_detid"
            energy: "genPh_E"
            hit_energy: "simHit_E"
        chunksize: 100
        batch_size: 100
        validation_set_size: 5000
        test_set_size: 30000
        prefetch_batches: 2
        num_workers_transform: 30
        num_workers_stack: 2
    pc:
        qf_seq_name: "pc_seq"
        rootprefix: "treeMaker/tree"
        preprocess_training: False
        braches:
            id: "simHit_detid"
            energy: "genPh_E"
            hit_energy: "simHit_E"
        keylist: ["genPh_E", "simHit_detid", "simHit_E"]
        cell_prop_keys: ["x", "y", "z"]
        chunksize: 100
        batch_size: 100
        validation_set_size: 5000
        test_set_size: 30000
        prefetch_batches: 2
        num_workers_transform: 30
        num_workers_stack: 2
